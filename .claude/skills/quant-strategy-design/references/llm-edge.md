# LLMのトレーディングにおけるエッジ リファレンス

## LLMが発揮できる具体的な優位性

### 1. ニュースセンチメント分析

**なぜエッジになるか**: 従来のセンチメント分析は単語の極性辞書に基づくものが多く、文脈を理解できなかった。LLMは文脈・皮肉・暗示を理解し、より正確なセンチメント判定が可能。

```
従来のセンチメント分析:
「Appleの売上は予想を下回った」→ ネガティブ

LLMのセンチメント分析:
「Appleの売上は予想を1%下回ったが、
サービス部門の成長率は過去最高を記録した」
→ 文脈を考慮すると「やや弱気だが、長期的にはポジティブ」
→ さらに「市場は短期的にネガティブ反応するが、
   サービス部門の成長にフォーカスが移り、数日後に回復する可能性」
```

**実装パターン**:
```python
def analyze_sentiment(news_text, model="claude-sonnet-4-5-20250929"):
    prompt = f"""以下のニュースを分析し、JSON形式で回答せよ。

ニュース: {news_text}

回答形式:
{{
  "sentiment_score": -1.0~1.0の数値,
  "confidence": 0.0~1.0の数値,
  "key_factors": ["要因1", "要因2"],
  "expected_impact": "short_term: ..., long_term: ...",
  "reasoning": "判断理由"
}}"""
    # Claude API呼び出し
    ...
```

### 2. 決算書の自然言語解析

**なぜエッジになるか**: 決算書（10-K, 10-Q）は数百ページに及ぶ。アナリストが全て読む前にLLMは要点を抽出できる。特に「Management Discussion & Analysis（MD&A）」セクションの定性的な分析に強い。

**エッジの時間窓**: 決算発表後30分〜数時間。この間に定性情報を分析し、定量データとの整合性をチェックできる。

**注意点**: 決算データそのもの（EPS等の数値）は瞬時に織り込まれるため、数値の分析ではエッジがない。LLMのエッジは「定性的な情報の解釈」にある。

### 3. マルチソース情報統合

**なぜエッジになるか**: 人間のアナリストは一度に限られた情報源しか処理できない。LLMは複数のソース（ニュース、決算書、SNS、アナリストレポート）を統合して判断できる。

```
情報統合の例:
ソース1 (ニュース): 「FRBが利下げを示唆」
ソース2 (決算書): 「テック企業のクラウド支出が増加傾向」
ソース3 (セクターデータ): 「テクノロジーセクターのRS改善」

統合判断: 「利下げ→成長株有利 + クラウド支出増 + RS改善
= テクノロジーセクターのオーバーウェイト推奨」
```

### 4. レジームチェンジの検出

**なぜエッジになるか**: テクニカル指標は過去データの延長で判断するため、市場の構造変化（レジームチェンジ）の検出が遅い。LLMはニュース・政策変更から構造変化の兆候をいち早く検出できる可能性がある。

```
レジームチェンジの例:
- 金融引き締め → 金融緩和への転換
- 低ボラティリティ → 高ボラティリティ
- セクターローテーション（テック → バリュー）

LLMの役割:
「FRB議長の発言のトーンが変化した」
「複数のFRBメンバーがハト派的発言」
「市場は織り込んでいないが、転換の兆候が増えている」
→ テクニカル指標が変化する前に対応可能
```

### 5. 異常検知・リスク警告

LLMは「いつもと違うパターン」を定性的に検出できる。

```
「今日のニュースフローは通常の3倍で、
ほとんどが地政学リスクに関連している。
過去にこのパターンが発生した際は、
VIXが平均30%上昇している。
ポジション縮小を推奨」
```

## LLMが苦手なこと

### 1. 高頻度取引（HFT）
- レイテンシ: LLM APIの応答時間は100ms-数秒。HFTはマイクロ秒の世界
- **結論: HFTには使えない。日次以上の時間軸が適切**

### 2. 純粋なテクニカル分析
- テクニカル指標の計算はPython/NumPyの方が正確で高速
- LLMは数値計算を間違えることがある
- **結論: テクニカル指標の計算はコードで行い、LLMは解釈に使う**

### 3. リアルタイムデータの処理
- LLMは学習データのカットオフがある
- リアルタイムの株価データの処理には向かない
- **結論: データ取得はAPI、分析の「判断」部分にLLMを使う**

### 4. 一貫性の保証
- 同じ入力でも異なる出力が返ることがある（temperature > 0の場合）
- **対策: temperature=0を使用し、構造化された出力（JSON）を強制する**

## LLM活用戦略の設計指針

```
LLMを使うべき部分:
├── ニュースの意味理解（センチメント + コンテキスト）
├── 決算書の定性分析（MD&A、リスク因子）
├── 複数情報源の統合判断
├── 市場レジームの定性的判断
└── 日次/週次の戦略レビュー・改善提案

LLMを使うべきでない部分:
├── テクニカル指標の計算 → Python/NumPy
├── 注文の執行 → Alpaca API直接
├── リアルタイムの価格データ処理 → ストリーミングAPI
├── 高頻度の売買判断 → ルールベースのコード
└── ポジション管理の計算 → SQLite + Python
```

## コスト管理

LLM API呼び出しのコストを事前に見積もること。

```
Claude Sonnet 1回の呼び出し:
- 入力: 2,000トークン（ニュース + プロンプト）
- 出力: 500トークン（分析結果）
- コスト: 約$0.01-0.03

日次10銘柄の分析:
- 10回 × $0.02 = $0.20/日
- 月次: 約$4-6

決算期の集中分析:
- 50銘柄 × $0.05 = $2.50/四半期決算期
```

**コスト削減テクニック**:
- 全ニュースではなく、事前フィルタリングで関連ニュースのみLLMに渡す
- 分析結果をキャッシュし、同じニュースを再分析しない
- Haikuモデルで一次スクリーニング、Sonnetで詳細分析の2段階構成
