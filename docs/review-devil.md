# DEVIL レビュー v3: 批判的分析と反論

> 「それ、本当？なぜそう言える？」 -- v2は改善されたが、改善自体が新たなリスクを生んでいる。複雑性の追加は必ずしも品質の向上ではない。

---

## 1. エグゼクティブサマリー

v2は私がv1で指摘した12の暗黙の前提に対して、一見すると網羅的に対処している。Phase 0の追加、12ヶ月300取引への延長、ベイズ的アプローチの導入、段階的目標設定、クラウド移行パス -- どれも方向性は正しい。

しかし、「それ、本当？なぜそう言える？」

v2の「改善」を精査すると、3つの根本的な問題が浮かび上がる。

**第一に、複雑性の爆発。** v1の「シンプルだが穴がある」設計は、v2で「網羅的だが実装不能」な設計に変貌した。4変数マクロモデル、セクター間相関マトリクス、ベイズ事後分布更新、Plattキャリブレーション、ウォークフォワードバックテスト、Kelly基準整合性検証 -- これらを個人開発者が1人で実装し、12ヶ月間維持運用できるのか？ v2は「やるべきこと」のリストとしては正しいが、「できること」のリストとしては非現実的だ。

**第二に、合意の質。** v2の「全員一致の合意事項」は、実際には「反論を段階的に薄めた妥協」に過ぎない。検証期間は私の12ヶ月要求に対してplanning-logでは「最低6ヶ月」で合意したはずが、strategy.mdとaction-plan.mdでは12ヶ月と記載されている。この不整合自体が、合意プロセスの脆弱性を示している。

**第三に、alpha仮説の検証基準の甘さ。** Phase 0のGo/No-Go基準が方向性精度60%に設定されているが、60%は取引コスト控除後にエッジを生まない可能性が高い。「60%でGo」は「撤退しないための言い訳」を組み込んでいるに等しい。

---

## 2. v2への反論と新規論点

### 論点1: Phase 0のGo/No-Go基準「60%」は本当に適切か？

**v2の主張**:
LLMセンチメントの方向性精度60%以上ならGo、60%未満ならNo-Go。60-70%は「条件付き続行」、70%以上でPhase 1に進行。

**反論**:
それ、本当？なぜ60%で「Go」と言えるのか？

60%の方向性精度で取引した場合の期待値を計算してみよう。

```
仮定: 方向性精度60%、平均利益ATR x 3.0 ≒ 4.5%、平均損失ATR x 2.0 x 1.3(スリッページ) ≒ 3.9%
期待リターン/トレード = 0.60 x 4.5% - 0.40 x 3.9% = 2.7% - 1.56% = 1.14%
年間50トレード x 1.14% x 1.0%リスク/3.9%損失 ≒ 年率1.46%

取引コスト（スプレッド0.03% x 2 + スリッページ）= 0.1%/トレード
年間コスト = 50 x 0.1% = 5%

APIコスト = $240/年、$10,000資金なら2.4%

税引前ネットリターン = 1.46% - 0.5%(スプレッド按分) ≒ 1%
APIコスト控除後 = 1% - 2.4% = **-1.4%**
```

つまり、**方向性精度60%では取引コストとAPIコストを控除するとマイナスリターン**になる。「60%でGo」は「損をしながら12ヶ月走り続ける」ことを意味する。

さらに、Phase 0の100件テストで精度60%を記録した場合の95%信頼区間は[50%, 70%]。真の精度が50%（コイントス以下）である可能性が統計的に否定できない。

**提案**:
- Go基準を**65%以上**に引き上げる。65%なら期待リターン/トレードが取引コストを上回る
- 100件ではなく**最低200件**でテストし、信頼区間を[±5%]に狭める
- Go判定の前に「取引コスト控除後の期待リターンがプラス」であることを数式で確認する追加条件を設ける
- 「条件付き続行」ゾーン（60-70%）を廃止する。このゾーンは「Goとは言えないがNo-Goと言いたくない」心理を制度化しているだけだ

---

### 論点2: 12ヶ月300取引でも統計的に不十分な可能性 -- 市場レジームの非定常性

**v2の主張**:
検証期間を3ヶ月100取引から12ヶ月300取引に延長。複数の市場環境を経験する。ベイズ的アプローチで信念を段階的に更新する。

**反論**:
それ、本当？12ヶ月で「十分」と言える根拠は何か？

v2は12ヶ月あれば「ブル/ベア/レンジ各1回以上経験」できると仮定しているが、**市場レジームは非定常過程**であり、12ヶ月で経験できるレジームは高々2-3種類に過ぎない。

具体的に問題を挙げる:

1. **2020年3月型のショック**: 過去20年で2-3回しか発生していない。12ヶ月で経験する確率は10-15%。経験しないまま「戦略はロバスト」と判断してリアル移行するリスク
2. **レジーム内のサブパターン**: 「ブル相場」にも「テック主導ブル（2023）」「ブロードベースブル（2024後半）」「インフレ下ブル」等がある。同じ「ブル」でも戦略パフォーマンスは大きく異なる
3. **PEAD効果のサイクル**: PEADのアルファは学術的に縮小傾向。12ヶ月前に有効だったエッジが12ヶ月後にはさらに縮小している可能性。**検証期間中のエッジと、リアル運用時のエッジは同一ではない**
4. **LLMの環境変化**: 12ヶ月後にはClaude 5やGPT-6が存在し、個人投資家のLLM利用が一桁増加している可能性がある。「先行者利益」どころか「後発者のコモディティ化された環境」で運用することになる

300取引はフリークエンシスト統計学的には改善だが、**市場の非定常性の前では根本的に無力**。ベイズ的アプローチも、事前分布のハイパーパラメータ次第で結論が変わる（論点5参照）。

**提案**:
- 12ヶ月の検証は「必要だが十分ではない」と明記する。12ヶ月後のリアル移行は「確信」ではなく「暫定的判断」に過ぎないことをドキュメントに記録
- **レジーム条件付きパフォーマンス**を評価する。「全期間のSR>0.8」ではなく、「ブル期のSR>0.5 かつ レンジ期のSR>0.3 かつ ベア期の損失<SPY」をリアル移行条件に追加
- 12ヶ月間でブル/ベア/レンジの3レジームのうち1つでも未経験なら、**リアル移行を延期**するルールを明文化
- 6ヶ月ごとにLLMセンチメント分析の精度を再テスト（Phase 0と同一手法）し、精度が劣化していればアラート

---

### 論点3: LLMセンチメントの「alpha decay」 -- 2026年時点でのエッジの消失

**v2の主張**:
「LLMセンチメント分析はコモディティ化しつつある。先行者利益の窓は狭い」と注意書きを追加。

**反論**:
「注意書き」で済ませていいのか？これはプロジェクトの存在意義に関わる根本問題だ。

2026年2月時点の現実を直視しよう:

1. **ChatGPTの月間アクティブユーザー**: 推定2億人以上。うち投資に利用する個人投資家は数百万人規模
2. **Bloomberg Terminal**: 既にAI搭載のセンチメント分析を標準機能として提供
3. **Copilot for Finance**: Microsoftが機関投資家向けにLLMベースの分析ツールを提供
4. **QuantConnect、Alpaca Forumなど**: LLMベースのトレーディングストラテジーのオープンソース実装が多数公開されている

v2は「先行者利益の窓は狭い」と認めながら、Phase 0のテストで精度60%以上なら「Go」としている。しかし、**Phase 0テストは過去データに対するものであり、将来のalphaを保証しない**。過去2年でLLMセンチメントにalphaがあったとしても、今後12ヶ月のペーパートレーディング中にそのalphaが消失する可能性は十分にある。

これは「LLMの精度」の問題ではなく、**「LLMが読む情報を全員が読んでいる」という構造的問題**だ。LLMは公開情報の分析しかできない。同じ公開情報を同じ品質で分析する競合が増えれば、alphaは数学的にゼロに収束する。

**提案**:
- Phase 0のテストに加えて、**リアルタイムのalpha decay測定**を月次で実施する。具体的には、LLMセンチメントのシグナルとその後5日間のリターンの相関を月次で追跡し、相関が3ヶ月連続で低下した場合は戦略を見直す
- 「LLMセンチメント単体」ではなく、**LLMが他の参加者と異なる分析を生成するケース**（コンセンサスとの乖離度が高いケース）に絞ってシグナルを出す設計に変更。LLMの価値は「正確さ」ではなく「コンセンサスとの差異」にある
- **フォールバック戦略をPhase 0と同時に設計**する。LLMセンチメントがコモディティ化した場合の代替戦略（テクニカルのみ、ファクター投資等）を事前に準備し、切替基準を定義

---

### 論点4: v2の「合意」は「妥協」ではないか？ -- 段階的目標設定は問題の先送り

**v2の主張**:
目標を段階的に設定。Phase 1: SR>0.3, Phase 2: SR>0.5, Phase 3: SR>0.8, リアル移行: SR>1.0。年率15%は長期的な野心目標として残す。

**反論**:
段階的目標設定は「改善」に見えるが、実態は「達成不可能な目標を達成可能に見せるための心理的トリック」ではないか？

Phase 1の目標「SR>0.3」は何を意味するか。シャープレシオ0.3はSPYの長期平均（約0.4-0.5）を下回る。つまり、**Phase 1の合格基準は「SPYのバイ&ホールドより悪い成績でもOK」**ということだ。これを「合格」と呼ぶのは、基準の切り下げに過ぎない。

さらに問題なのは、段階的目標が**サンクコスト効果を増幅する構造**になっていること:

1. Phase 1（1-3ヶ月）: SR 0.3で「合格」→ 開発投資を正当化する根拠を得る
2. Phase 2（4-6ヶ月）: SR 0.5で「改善している」→ 追加投資を正当化
3. Phase 3（7-12ヶ月）: SR 0.8に到達しなくても「SR 0.5-0.7なら改善の余地がある」と延長の口実になる
4. 12ヶ月後: 「もう少しパラメータを調整すればSR 1.0に届く」→ 永遠に終わらない

各Phaseの「合格」が次のPhaseへの投資を正当化し、撤退がますます困難になる。これは段階的目標の構造的な罠だ。

リアル移行基準のSR>1.0についても、v2のKelly基準分析が示す通り、年率8-12%のリターン目標とSR>1.0は整合しない（SR 1.0には年率15%以上が必要）。**自分自身で「年率15%は非現実的」と認めながら、リアル移行基準にSR>1.0を残すのは自己矛盾**だ。

**提案**:
- 段階的目標の「合格」を「撤退しない条件」と明確に区別する。Phase 1で「SR>0.3だから合格」ではなく「SR<0の場合のみ即時撤退、0-0.3は要注意ゾーン」と表現を変える
- リアル移行基準をSR>0.8に統一し、SR>1.0の記載を削除する（strategy.mdのv2変更で既にSR>0.8に修正済みだが、planning-logとの不整合が残っている）
- **各Phaseに「No-Go基準」を明示的に追加**する。「合格」だけでなく「失格」条件を各Phaseに設定し、該当したら強制撤退

---

### 論点5: ベイズ的アプローチの事前分布設定のアービトラリネス

**v2の主張**:
事前分布 SR ~ Normal(0, 0.5)（スキルなしが事前の期待）を取引結果で更新。P(SR > 0.5 | data) > 90%をリアル移行条件に。

**反論**:
それ、本当？事前分布の選択が結論を変えることを認識しているか？

事前分布 Normal(0, 0.5) の意味は「シャープレシオが-1.0〜+1.0の範囲に95%の確率で収まる」という信念だ。しかし:

1. **なぜ平均0なのか？** 「スキルなし」の事前分布として0は妥当に見えるが、取引コストを考慮すると「スキルなし」のSRはマイナスであるべき（取引コスト分だけリターンがマイナスになるため）。事前分布を Normal(-0.3, 0.5) にすれば、リアル移行に必要な取引数が増える
2. **なぜ標準偏差0.5なのか？** 0.3にすれば事前情報がより強くなり、同じデータでもP(SR > 0.5 | data)が低くなる。1.0にすれば弱い事前分布となり、少ない取引数でも「Go」判定が出やすくなる。**標準偏差の選択は恣意的であり、結論を操作できる**
3. **正規分布は適切か？** SRの分布は非正規（右裾が重い）であることが知られている。対数正規分布や、Bailey & Lopez de Prado (2012) のDeflated Sharpe Ratioの方が理論的に適切

ベイズ的アプローチは「少ないサンプルでも合理的な判断ができる」と聞こえるが、実際には**事前分布の選択が結論を左右する**。事前分布を「合理的に」選ぶための根拠が循環論法になるリスクがある。

**提案**:
- 事前分布の感度分析を必須にする。Normal(0, 0.3), Normal(0, 0.5), Normal(0, 1.0), Normal(-0.3, 0.5) の4つの事前分布で事後確率を比較し、**全てでP(SR > 0.5) > 90%**を満たした場合にのみリアル移行を許可
- ベイズ的アプローチを「唯一の判断基準」にせず、フリークエンシストのブートストラップ信頼区間と併用。**両方の基準を満たす**ことを要求（v2のplanning-logでは「併用」と記載されているが、strategy.mdではベイズ単体の条件が書かれている。この不整合を修正すべき）
- 事前分布の選択根拠を文書化し、Phase 0終了時に確定させる。以降、事前分布の変更は禁止

---

### 論点6: Reconciliationは本当に「Alpacaを正」で良いか？

**v2の主張**:
「Alpaca API = Source of Truth」。Reconciliation時に差異があればAlpacaを正として自動修正。

**反論**:
それ、本当？Alpaca側にバグがないと仮定できるか？

v2のReconciliationは「Alpacaが常に正しい」前提で設計されているが:

1. **Alpaca APIのバグ**: 過去にAlpaca APIでポジション表示の不整合が報告されている。`get_all_positions()` が一時的に不完全なデータを返すケースが文書化されている
2. **APIのレースコンディション**: ストップロス注文の約定処理中に `get_all_positions()` を呼ぶと、クローズ途中のポジションが「存在する」「存在しない」のどちらにもなりうる
3. **ネットワーク一時障害**: APIレスポンスが途中で切断された場合、部分的なデータでReconciliationが走り、正常なポジションを「存在しない」と誤判定して閉じる可能性
4. **手動操作の正当性**: 「Alpacaにあるがローカルにない → 手動追加 or 記録漏れ → DBにレコード追加」とあるが、手動操作でAlpaca側にテスト用のポジションを作成した場合、自動的にDBに追加されてトレーディング対象になってしまう

**提案**:
- Reconciliation時に自動修正を行う前に、**差異の内容をログに記録し、一定の閾値を超える差異（例: ポジション数が3以上不一致、または存在しないはずのポジションが3つ以上Alpacaにある）の場合は自動修正を停止してアラートのみ送信**する
- Alpacaの `get_all_positions()` を**2回連続で呼び出し**、結果が一致した場合のみReconciliationを実行する（レースコンディション対策）
- 手動操作によるポジション追加を防ぐため、DBに `source` カラム（'agent' / 'reconciliation' / 'manual'）を追加し、reconciliation由来のポジションには自動的にストップロスを設定するロジックを追加

---

### 論点7: テスト95%カバレッジの罠

**v2の主張**:
リスク管理モジュールのカバレッジ95%以上を目標。テストなしにペーパートレーディングを開始してはならない。

**反論**:
カバレッジ95%は「安全」に聞こえるが、それ、本当？

カバレッジ95%が保証するのは「コードの95%の行が最低1回実行された」ことだけだ。以下のケースはカバレッジ95%でも見逃される:

1. **境界値のバグ**: `if risk > 0.015` と書くべきところを `if risk >= 0.015` と書いた場合、テストが `risk = 0.02` のみを検証していればカバレッジ100%だがバグは検出されない
2. **状態遷移のバグ**: 回路ブレーカーがLevel 1→Level 2→解除→再度Level 1のような複雑な状態遷移を正しくハンドルするかは、カバレッジでは測定できない
3. **並行性のバグ**: ファイルロックのタイムアウト、Reconciliation中の注文実行など、タイミング依存のバグはユニットテストでは再現困難
4. **データ品質のバグ**: Alpaca APIが返す `qty` が文字列（"100"）であることを知らずに整数演算すると、テストでは `int(100)` を渡すため問題なく通るが、本番では失敗

カバレッジを追求すること自体がリスクになる。カバレッジの数字を上げるために**テストの質が低下する**（assert文なしのテスト、異常系を無視したテスト等）現象は開発現場で頻繁に観察される。

**提案**:
- カバレッジ目標を「95%以上」から「risk_managerは95%、その他は80%」に変更（v2のsystem-design.mdではこのように書かれているが、ARCHの最終提言では「95%以上」と記載。不整合を修正）
- カバレッジに加えて**Mutation Testing**（コードの条件式を反転させてテストが失敗するかを検証）を導入。少なくともリスク管理モジュールに適用
- **プロパティベーステスト**（hypothesis等）の導入。「ポジションサイズは常に0以上」「ストップロスは常にエントリー価格未満」等の不変条件をランダムデータで検証
- 「テストがあるからバグがない」という過信を防ぐため、**ペーパートレーディング最初の2週間を「カナリアリリース」**と位置付け、1ポジションのみで運用し、全ての注文を手動で検証する期間を設ける

---

### 論点8: 「プランB」は本当に実行されるか？ -- サンクコスト効果の過小評価

**v2の主張**:
失敗時のフォールバック（プランB）を事前に定義。LLM精度不足→テクニカルのみ、SR<0.3→セクターモメンタム戦略に転換、15%ドローダウン→SPYバイ&ホールドに切替。

**反論**:
プランBの存在は心理的安全弁だが、それ、本当に実行されるか？

行動経済学の研究（Arkes & Blumer, 1985; Staw, 1976）が示す通り、人間は「事前に撤退基準を決めても、サンクコストが増加すると撤退できない」。これは知識の問題ではなく、認知バイアスの問題だ。

v2のプロジェクトにおけるサンクコストを見積もってみよう:

| 時点 | 累積投資（開発時間） | 累積投資（APIコスト） | プランBの心理的障壁 |
|------|---------------------|---------------------|---------------------|
| Phase 0終了（2週間） | 80時間 | $120 | 低い（まだ始まっていない） |
| Phase 2終了（6週間） | 240時間 | $150 | 中程度（コードが動き始めた） |
| Phase 4終了（10週間） | 400時間 | $200 | 高い（システムが完成した） |
| ペーパー6ヶ月目 | 600時間 | $350 | **極めて高い**（半年分のデータがある） |
| ペーパー12ヶ月目 | 800時間 | $500 | **撤退不能**（1年を費やした） |

800時間の開発時間を時給$50で換算すると$40,000。$10,000の運用資金に対して4倍の機会コストを投じている。この時点で「alphaがないのでSPYに切り替えましょう」と言えるか？

v2には月次チェックポイントと撤退基準が定義されているが、**撤退判断を下すのは誰か？** 自分自身だ。そして自分自身は、800時間の投資を「無駄だった」と認めたくないバイアスを持つ。

**提案**:
- **撤退判断のトリガーをシステム化**する。月次チェックポイントで撤退基準に抵触した場合、trading_agent.pyが自動的に新規エントリーを停止し、Slackに「撤退基準に抵触しました。手動で再開するには config.toml の `force_resume = true` を設定してください」と通知する。再開のハードルを意図的に上げることで、撤退バイアスに対抗
- **累積APIコスト$300の「中間撤退レビュー」**を追加（v2の$500上限に加えて）。$300時点で「残りの$200で何が検証できるか」を強制的にレビューし、検証計画を更新
- **第三者レビューを制度化**する。月次で、Claude CLIの別セッション（レビュアーとしてのDEVILロール）にパフォーマンスデータを入力し、「このプロジェクトを続けるべきか」の客観的評価を受ける。ただし、LLMに撤退判断を委ねる皮肉は認める
- **Phase 0の時点でプランBのプロトタイプを作る**。テクニカルのみの戦略のバックテストを Phase 0 と同時に実施し、「プランBでもSPY+3%程度は出せる」ことを確認した上でプロジェクトを開始する。プランBが機能しないなら、プロジェクト自体が無意味

---

### 論点9: v2で追加された複雑性自体がリスク -- 個人開発者に過剰では？

**v2の主張**:
4変数マクロモデル、セクター間相関マトリクス、ベイズ事後分布更新、Plattキャリブレーション、ウォークフォワードバックテスト、Kelly基準整合性検証、ブートストラップ法、Deflated Sharpe Ratio、Bonferroni補正、exchange_calendars、Reconciliation、3重冪等性防御、ブラケット注文、Partial Fill対応、多層ストップロス、VIX連動ポジション制限、段階的撤退...

**反論**:
これを1人で実装して1人で運用するのか？それ、本当？

v2のaction-plan.mdは「5人のAIエージェント」が担当者として列挙されているが、実装するのは1人の人間だ。STRAT/QUANT/RISK/ARCH/DEVILは実装してくれない。

v2で追加された機能を実装工数で見積もると:

| 機能 | 推定実装工数 | 推定テスト工数 | 維持工数/月 |
|------|-------------|-------------|-------------|
| 4変数マクロモデル | 8h | 4h | 2h（FRED APIの仕様変更対応） |
| セクター間相関マトリクス | 12h | 6h | 4h（月次更新） |
| ベイズ事後分布更新 | 16h | 8h | 2h |
| Plattキャリブレーション | 8h | 4h | 2h（月次更新） |
| ウォークフォワードバックテスト | 24h | 12h | 4h |
| ブートストラップ法 | 4h | 2h | 1h |
| Reconciliation | 12h | 8h | 2h |
| 3重冪等性防御 | 8h | 6h | 1h |
| ブラケット注文 + Partial Fill | 16h | 8h | 2h |
| Slack Webhook + 4段階アラート | 8h | 4h | 1h |
| **合計** | **116h** | **62h** | **21h/月** |

開発だけで178時間（4.5週間のフルタイム作業）。月次維持に21時間（約3営業日）。12ヶ月で252時間の維持作業。

**これに加えて**、毎月の:
- 月次チェックポイント評価（4h）
- キャリブレーションプロット更新（2h）
- 相関マトリクス更新（2h）
- ベイズ事後分布更新（2h）
- 戦略改善サイクル（8h）

月間合計: **39時間/月**。週10時間。**副業としても重い。**

v1の「シンプルだが穴がある」設計は、v2で「理想的だが実装しきれない」設計に変わった。実装しきれない機能は存在しないのと同じだ。

**提案**:
- v2の機能を**「Phase 1必須」「Phase 3追加」「リアル移行時追加」の3段階**に明確に分類し、初期実装のスコープを大幅に縮小
- 以下を「Phase 1必須」から除外（Phase 3以降に延期）:
  - セクター間相関マトリクス → 「同一セクター2銘柄制限」で代替
  - ベイズ事後分布更新 → ブートストラップ法のみで判断
  - Plattキャリブレーション → 生のキャリブレーションプロットで十分
  - 4変数マクロモデル → 2変数（200日MA + VIX）で開始し、必要に応じて拡張
- **「MVP（Minimum Viable Product）」思想**をプロジェクトに導入。最初の3ヶ月は「動く最小限のシステム」で運用し、複雑な機能は運用データに基づいて追加するか判断
- 「やるべきことリスト」ではなく「やらないことリスト」を作成し、スコープクリープを防止

---

## 3. 最終提言（優先順位付き3項目）

### 提言1: Phase 0のGo/No-Go基準を厳格化し、alpha decay測定を組み込め（最重要）

Go基準を60%から65%に引き上げ、テストサンプルを100件から200件に拡大せよ。60%でGoと判断しても、取引コストとAPIコスト控除後にリターンがマイナスになる可能性が高い。加えて、ペーパートレーディング開始後は月次でalpha decayを測定し、LLMセンチメントのエッジが縮小していないか継続的に監視せよ。Phase 0で検証すべきは「今alphaがあるか」だけでなく「12ヶ月後にもalphaが残っているか」の見通しだ。

### 提言2: 複雑性を削減し、MVP思想で初期実装スコープを半減せよ

v2は理想的なシステムの設計書であり、実装可能なシステムの設計書ではない。4変数マクロモデル、セクター間相関マトリクス、ベイズ事後分布、Plattキャリブレーションはいずれも「あれば良い」機能であり「なければ死ぬ」機能ではない。初期3ヶ月は2変数マクロ + 単純なセクター制限 + ブートストラップ法のみで運用し、複雑な機能は「運用データが必要性を証明した場合にのみ」追加せよ。やるべきことの半分を捨てる勇気を持て。

### 提言3: 撤退判断をシステム化し、人間の認知バイアスに対抗せよ

月次チェックポイントと撤退基準は紙の上に書いてあるだけでは機能しない。撤退基準に抵触した場合にtrading_agent.pyが自動的に新規エントリーを停止する仕組みを実装せよ。再開には手動で設定ファイルを変更する必要があるようにし、撤退のハードルを下げ、継続のハードルを上げよ。800時間の開発投資の後に「やめる」判断を人間の意志力に委ねるのは、行動経済学が否定済みの楽観だ。

---

*「それ、本当？なぜそう言える？」 -- v2はv1より確実に良い。しかし、v2の改善が「十分」かと問われれば、答えはNoだ。最大のリスクは市場でも技術でもない。「合理的に見える計画を、非合理的な人間が実行する」という構造そのものだ。この構造に対抗する唯一の手段は、撤退をシステムに組み込み、複雑性を削り、そして常に自分自身に問い続けることだ -- 「それ、本当？なぜそう言える？」*

---

*レビュー実施: DEVIL（反論者・デビルズアドボケイト）*
*レビュー日: 2026-02-11*
*対象文書: docs2/strategy.md, docs2/system-design.md, docs2/action-plan.md, docs2/planning-log.md, docs2/review-devil.md, docs2/review-strat.md, docs2/review-quant.md, docs2/review-risk.md, docs2/review-arch.md*
