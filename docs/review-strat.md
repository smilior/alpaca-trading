# STRAT レビュー v3: 市場戦略観点からの深掘り改善提案

> 「エッジはどこにあるか？」 -- v2で骨格は整った。v3ではエッジの持続可能性と実装精度を追求する。

---

## エグゼクティブサマリー

v2は私（STRAT）の提案を含む5名のレビューを忠実に反映し、Phase 0の追加、目標リターンの現実化、4変数マクロレジームモデル、銘柄ユニバース拡大、セクターETF補完戦略の具体化など、骨格として大きく改善された。しかしv2を精読すると、「方向性は正しいが、実行プロトコルの粒度が粗い」箇所が複数存在する。特にPhase 0の手順書は「何をやるか」は書かれているが「どうやるか」が不十分であり、このままでは検証の質にバラツキが出る。また、LLMセンチメントのエッジは時間とともに確実に消失する（alpha decay）にもかかわらず、その速度の定量モデルがない。銘柄ユニバースの「段階的拡大」の判断基準も曖昧で、恣意的な判断が入り込む余地がある。v3では、これらの「骨格と実装の隙間」を埋めることに集中する。

エッジはどこにあるか？ -- v2の答えは「決算オーバーリアクション + LLMの文脈理解」。v3の問いは「そのエッジはいつまで持つか、どう測り続けるか、枯渇したときに何をするか」だ。

---

## v2からの残課題と新規論点

### 論点1: Phase 0（alpha仮説検証）の実行プロトコルの精緻化

#### 現状の問題

v2でPhase 0が追加されたのは大きな前進だが、実行プロトコルとして以下が不足している:

1. **決算レポートの取得方法が未定義**: 「過去6ヶ月の決算発表データ100件を収集」とあるが、どこから何の形式で取得するのか。10-K/10-Qの全文か、プレスリリースか、アナリスト向けサマリーか。LLMに渡すテキストの品質と範囲がセンチメント精度を直接左右する。
2. **LLMプロンプトの標準化が未定義**: Phase 0で使うプロンプトとPhase 5（本番）で使うプロンプトが異なると、精度検証の意味がなくなる。プロンプトのバージョンロックが必要。
3. **時間バイアスの制御が不十分**: Claude CLIに過去の決算レポートを渡す場合、LLMのトレーニングデータに含まれている可能性がある。LLMが「決算後に株価が上がった」という事実を知っている状態でセンチメント判定すれば、精度は過大評価される。
4. **サンプリング方法が未定義**: 100件をどう選ぶのか。ランダムか、セクター均等か、シグナルが出やすい銘柄を優先するのか。サンプリングバイアスが検証結果を歪める。
5. **Go/No-Go判断の意思決定プロセス**: 誰が、どのように、最終判断するのか。数値基準はあるが、境界ケース（精度59.5%）での判断ルールがない。

#### 改善提案

```
Phase 0 実行プロトコル（詳細版）

Step 0: プロンプト設計（Day 1-2）
  - 本番用プロンプト（prompts/trading_decision.md）のv1.0をフリーズ
  - Phase 0専用のラッパープロンプトを作成:
    「以下の決算情報のみに基づいて判断せよ。
     株価の事後的な動きに関する知識は使うな。
     判定日は {earnings_date} として扱え。」
  - プロンプトにタイムスタンプ制約を明示的に含める

Step 1: データ収集（Day 3-5）
  - ソース: SEC EDGAR（10-Q/10-K）+ Alpaca News API（決算プレスリリース）
  - 対象: S&P500構成銘柄のうちユニバース条件を満たす銘柄
  - サンプリング: 層化抽出法
    - 11セクター x 各9件 = 99件（端数調整で100件）
    - 各セクター内ではランダム選定
    - 期間: 直近6ヶ月（2四半期分をカバー）
  - データ項目: 決算プレスリリース全文、EPS実績/予想、売上実績/予想、
    ガイダンス（あれば）、発表日翌1/3/5営業日のリターン
  - 除外条件: M&A発表と決算が同日の銘柄（ノイズ排除）

Step 2: LLMセンチメント分析実行（Day 6-8）
  - 各決算レポートに対してClaude CLIでセンチメント分析を実行
  - 出力: {sentiment: positive/negative/neutral, confidence: 0-100,
    key_drivers: [...], risk_factors: [...]}
  - コスト: 100件 x ~$0.03 = ~$3
  - 実行ログ: 全入力・全出力をJSON保存（再現性確保）

Step 3: 時間バイアス検定（Day 9）★v3新規★
  - 検証方法: 20件の「未来データ」テスト
    - 直近1週間に発表された決算（LLMのトレーニングデータに含まれない可能性が高い）
    - この20件の精度と、過去6ヶ月100件の精度を比較
    - 有意な差（>10pp）があれば時間バイアスの存在を示唆
  - 差がある場合: 過去データの精度に「時間バイアス割引」を適用
    補正精度 = 過去精度 - (過去精度 - 直近精度) * 0.5

Step 4: ベースライン比較（Day 10-12）
  - FinBERT: 同一100件で実行（ローカル、無料）
  - VADER: 同一100件で実行（ローカル、無料）
  - ナイーブモデル: 「常にポジティブ」「EPS beatなら常にポジティブ」
  - 比較: McNemar検定（ペアデータのため、カイ二乗検定より適切）

Step 5: Go/No-Go判断（Day 13-14）
  判断マトリクス（境界ケース対応）:
  | LLM精度      | vs FinBERT差  | 判断           |
  |-------------|--------------|----------------|
  | >= 65%      | >= +5pp      | Go（確信的）     |
  | >= 60%      | >= +5pp      | Go（慎重に）     |
  | >= 60%      | < +5pp       | 条件付Go: 追加100件で再検証 |
  | 55-59%      | >= +10pp     | 条件付Go: 追加100件で再検証 |
  | < 55%       | any          | No-Go          |

  - 条件付Goの場合: 追加100件（コスト$3）で再検証し、
    合計200件で上記基準を再判定。2回目も条件付ならNo-Go
```

#### エッジへの影響

Phase 0の実行品質がプロジェクト全体の方向を決定する。プロトコルが粗いと「精度が高く見えるが実は時間バイアス」という最悪の誤判断が起きる。特に時間バイアス検定（Step 3）は、LLMの事前知識汚染を検出する唯一の手段であり、省略してはならない。エッジの有無を正しく判定できなければ、以降の全ての設計が空中楼閣になる。

---

### 論点2: LLMセンチメントのalpha decay（エッジ消失速度）の定量モデル

#### 現状の問題

v2のstrategy.mdで「LLMセンチメント分析はコモディティ化しつつある。先行者利益の窓は狭い」と注意喚起しているが、これは定性的な警告にとどまっている。エッジはどこにあるか？ -- この問いの前に「エッジはいつまであるか？」を問うべきだ。

LLMセンチメントのalpha decayを駆動するメカニズム:

1. **参加者増加**: GPT/Claude/Geminiでセンチメント分析する個人・機関が指数関数的に増加中。2024年のNLP in Finance関連論文数は2022年の3倍以上。
2. **LLMの一般化**: Claude/GPTの出力はモデルが同じなら同一入力に対して類似出力を返す。つまり、同じプロンプトを使う参加者が増えるほど、同一方向のポジションが集中し、エッジが消失する。
3. **市場の適応**: LLMセンチメントが一方向に傾くパターンをHFTが学習し、先回りする（front-running）。
4. **PEADの縮小トレンド**: 学術研究でPEADのalpha自体が過去30年で縮小傾向にあることが報告されている（McLean & Pontiff 2016: 学術論文発表後にアノマリーの平均リターンが58%縮小）。

#### 改善提案

```
Alpha Decay モニタリングフレームワーク

1. 月次精度トラッキング:
   - LLMセンチメント精度を月次で測定（混同行列 + 方向性精度）
   - 精度の3ヶ月移動平均を計算
   - 移動平均が2ヶ月連続で低下 → Alpha Decay Warning
   - 移動平均がPhase 0基準（60%）に到達 → Alpha Decay Critical

2. Edge Half-Life（エッジ半減期）の推定:
   - Phase 0精度をP0、月次精度をPtとする
   - ベースライン精度（ランダム = 33.3%、ナイーブ = 推定50%）をPbaseとする
   - エッジ = Pt - Pbase
   - エッジ半減期 = 月数t where (Pt - Pbase) = (P0 - Pbase) / 2
   - 6ヶ月分のデータが蓄積されたら回帰分析で半減期を推定
   - 半減期 < 12ヶ月の場合: 戦略の根本的再設計が必要

3. 「エッジ枯渇」時のプランC ★v3新規★:
   シナリオ: LLM精度が55-60%に低下（エッジは残存するが薄い）
   対応:
   a. LLMの役割を「エントリーシグナル」から「リスクフィルター」に切替
      - テクニカル/モメンタムでエントリー候補を選定
      - LLMは「この銘柄にネガティブリスクがないか」のスクリーニングに使用
      - エッジの源泉をLLMからテクニカルに移転
   b. プロンプトの差別化を追求
      - 汎用的な「センチメント判定」ではなく、
        「アナリストコンセンサスとの乖離度」「一時的要因vs構造的要因の判別」
        など、LLMの文脈理解力が真に発揮される特化型プロンプトに進化
      - コモディティ化された「ポジティブ/ネガティブ」判定から脱却
   c. マルチモデルアンサンブル
      - Claude + GPT-4 + Gemini の3モデルで同一判定
      - 3モデル一致 = 高確信、2:1 = 中確信、バラバラ = 見送り
      - 単一モデル依存からの脱却（DEVIL指摘のモデル変更リスク軽減にも寄与）
```

#### エッジへの影響

alpha decayを「不可避だが管理可能な現象」として扱うことで、エッジ消失にパニックしない運用体制を構築できる。半減期の推定は6ヶ月以上のデータが必要だが、月次精度トラッキングは初月から開始できる。エッジの持続可能性を定量的に監視する仕組みがなければ、「気づいたらエッジがゼロだった」という最悪のシナリオを防げない。

---

### 論点3: 銘柄ユニバース段階的拡大の判断基準の精緻化

#### 現状の問題

v2では「30銘柄でスタートし、月間シグナル頻度が8件未満なら段階的に拡大（30→50→80）」と合意されたが、以下が曖昧:

1. **「月間シグナル頻度」の定義**: エントリーシグナルのみか、エントリー候補（Stage 1通過）を含むか。LLMポジティブ判定数か、テクニカルフィルター通過後の最終エントリー数か。
2. **拡大のタイミング**: 1ヶ月目終了時に即判断するのか、2ヶ月分のデータを待つのか。
3. **追加銘柄の選定基準の優先順位**: アナリストカバレッジ5人以上、時価総額$20B以上、日次平均出来高200万株以上の3条件は合意済みだが、条件を満たす銘柄が50以上ある場合の選定方法が未定義。
4. **拡大の「逆戻り」条件**: 50銘柄に拡大した後、シグナル品質が低下した場合に30銘柄に戻す基準がない。

#### 改善提案

```
銘柄ユニバース段階的拡大プロトコル

定義の統一:
  - 「シグナル頻度」= Stage 2通過後の最終エントリーシグナル数/月
    （Stage 1のLLMポジティブ判定数ではない。最終シグナルで測るべき）
  - 「シグナル品質」= エントリー後5日リターンの平均値

拡大判断マトリクス:
  | 月間シグナル数 | シグナル品質   | 判断                |
  |-------------|-------------|---------------------|
  | >= 12       | >= +0.5%    | 現状維持（十分）       |
  | >= 8        | >= +0.5%    | 現状維持             |
  | >= 8        | < +0.5%     | 拡大せず、フィルター見直し |
  | 5-7         | >= +0.5%    | 拡大検討（下記手順）    |
  | < 5         | any         | 即時拡大             |

拡大手順:
  1. 追加候補銘柄をスクリーニング（3条件 + ユニバース条件）
  2. 候補銘柄を以下の優先順位でランキング:
     a. 過去4四半期のEarnings Surprise頻度（高い方が上位）
     b. ATRパーセンタイル（高い方が上位）
     c. 決算発表日が次の決算シーズンと重ならない（分散効果）
  3. 上位20銘柄を追加（30→50）
  4. 2ヶ月運用後に再評価

逆戻り条件 ★v3新規★:
  - 拡大後2ヶ月の追加銘柄群の平均シグナル品質が、
    既存銘柄群の平均シグナル品質を1pp以上下回る場合:
    → 下位パフォーマンス銘柄10銘柄を除外
  - 拡大後の全体シグナル品質が拡大前を下回る場合:
    → 拡大前のユニバースに戻す

評価タイミング:
  - 初回判断: 2ヶ月目終了時（1ヶ月目はデータ不足）
  - 以後: 毎月末の月次チェックポイントで評価
```

#### エッジへの影響

銘柄ユニバースの拡大は「シグナル量の増加」と「シグナル品質の希釈」のトレードオフ。エッジはどこにあるか？ -- LLMセンチメント分析の精度は、アナリストカバレッジが厚く情報量が多い銘柄で最も高い。ユニバースを無秩序に拡大すると、LLMの分析材料が乏しい銘柄が混入し、エッジが薄まる。拡大の品質管理なしに量を追求すれば、統計的有意性のためのサンプル数は確保できるが、そのサンプルの質が劣化する本末転倒が起きる。

---

### 論点4: マクロレジーム4変数モデルの重み付けと運用

#### 現状の問題

v2で4変数モデル（S&P500 vs 200MA、VIX、イールドカーブ、クレジットスプレッド）への拡張が採用されたが、判定ロジック「4変数中3つ以上が同一レジームなら確定。2:2なら"レンジ"」は全変数を等加重で扱っている。

問題点:
1. **4変数の予測力は等しくない**: VIXは短期的なリスク認知を反映するがmean-revertingであり、イールドカーブは景気循環の先行指標で半年以上先を予測する。同じ重みで投票させるのは情報の質の違いを無視している。
2. **閾値の根拠が弱い**: VIXの18/25、クレジットスプレッドの350bp/500bpなど、閾値設定の根拠が「経験則」レベル。過去データでの検証がない。
3. **レジーム遷移中の挙動が不安定**: 2:2の「レンジ」判定が頻発すると、ポジションサイズが毎日変動し、取引コストが増加する。
4. **データの遅延問題**: FRED APIのマクロ指標は発表日ベースでリアルタイムではない。イールドカーブは日次更新だが、クレジットスプレッドは数日遅延する場合がある。

#### 改善提案

```
マクロレジーム判定の改善

1. 段階的アプローチ（v3推奨）:
   Phase 1-3: 等加重投票方式を維持（v2のまま）
   理由: データドリブンの重み最適化には最低12ヶ月のデータが必要。
   少ないデータでの最適化はオーバーフィッティングの温床。

   Phase 4以降: データドリブン重み付けへの移行を検討
   手法: 過去のレジーム判定と実際の戦略パフォーマンスの関係を
   ロジスティック回帰で分析し、各変数の予測寄与度を重みに反映。

2. 閾値のバックテスト検証:
   - 過去10年分のFREDデータでVIX/イールドカーブ/クレジットスプレッドの
     閾値を±20%変動させた場合のレジーム分類結果を比較
   - S&P500の翌3ヶ月リターンとの相関が最も高い閾値セットを特定
   - ただし、最適閾値ではなく「安定的に高い相関を示す範囲」を採用
     （ポイント最適化ではなくロバスト最適化）

3. レジーム遷移のヒステリシス（遅延確定）★v3新規★:
   問題: 2:2判定が日替わりで変動し、ポジションサイズが不安定になる
   対策:
   - レジーム確定には「3営業日連続で同一判定」を要求
   - 遷移中（未確定）はレンジ扱い（ポジションサイズ50%縮小）を維持
   - レジーム変更ログをDBに記録し、変更頻度を月次でモニタリング
   - 月間レジーム変更が4回以上 → 閾値の再キャリブレーションを実施

4. データ遅延への対処:
   - クレジットスプレッド: ICE BofAデータ（FRED経由）は1-2日遅延
   - 対策: 遅延データにはフラグを立て、遅延2日以上の場合は
     該当変数を投票から除外（3変数中2以上で判定）
   - 将来的にはBloomberg/Refinitivの日次データに移行を検討
     （ただしコストとの兼ね合い）
```

#### エッジへの影響

マクロレジーム判定はポジションサイズを直接制御するため、判定の安定性がリスク調整後リターンに大きく影響する。エッジはどこにあるか？ -- レジーム判定そのものにエッジがあるのではなく、「間違ったレジームでポジションを取らない」防御力がエッジを守る。等加重投票は理論的には最適ではないが、データ不足の初期段階では最もロバストな選択。重み最適化への移行は12ヶ月以上のデータ蓄積後に行うべきであり、v2の段階で等加重を選択したのは正しい。

---

### 論点5: セクターETF補完戦略とメイン戦略の資本配分最適化

#### 現状の問題

v2でセクターETF補完戦略が「セクターモメンタム戦略」として具体化されたが、メイン戦略（個別株決算ドリブン）との資本配分ルールに以下の問題がある:

1. **「決算シーズン中はETF 0ポジション」は資本効率を犠牲にしすぎる**: 決算シーズンは約3-4週間。5ポジション全てが決算シグナルで埋まるとは限らず、2-3ポジション分の資本が遊ぶ可能性がある。
2. **ETFとメイン戦略のリスクプロファイルが異なる**: ETFのセクターモメンタムは保有期間15日・ATR x 2.5で、個別株（3-5日・ATR x 2.0）より長期・広ストップ。ポジションサイズ「個別株の50%」は直感的だが、リスク等価（Equal Risk Contribution）で計算した方が合理的。
3. **セクターETFとメイン戦略の相関リスク**: XLKのETFロング + AAPL個別株ロングは実質的にテクノロジーセクターへの二重エクスポージャー。共存ルールにこの点の考慮がない。
4. **ETFモメンタム戦略のエッジ検証がない**: メイン戦略にはPhase 0の検証があるが、ETF戦略の検証プロセスが未定義。

#### 改善提案

```
セクターETF補完戦略の改善

1. 資本配分の柔軟化:
   旧: 決算シーズン中はETF 0ポジション
   新:
   | 期間            | 個別株上限 | ETF上限 | 条件                    |
   |----------------|----------|--------|------------------------|
   | 決算シーズン中    | 5        | 1      | ETFはメイン銘柄と異なるセクターのみ |
   | 決算シーズン外    | 2        | 3      | セクター重複なし条件        |
   | マクロイベント週   | 2        | 2      | FOMC/CPI/雇用統計週      |

   総エクスポージャー上限: 常に80%を維持

2. リスク等価ポジションサイジング ★v3新規★:
   旧: ETFポジションサイズ = 個別株の50%（固定比率）
   新: リスク等価方式

   ETF_position_risk = ETF_qty * ETF_ATR * ETF_SL_multiplier
   Stock_position_risk = Stock_qty * Stock_ATR * Stock_SL_multiplier

   各ポジションのリスク金額を総資金の1.0%で統一する。
   ETFのATRが個別株の約40-60%であることを考慮すると、
   ETFのポジションサイズは自然に個別株の1.5-2.5倍になる。
   → 「50%」ではなく、リスクベースで自動計算

3. セクター重複排除ルール ★v3新規★:
   - ETFポジションと同一セクターの個別株ポジションは合計で
     セクター配分上限（例: テクノロジー30%）を超えないこと
   - XLKをロングしている場合、テクノロジー個別株は最大1銘柄
   - ETF-個別株間の相関を月次で計算し、相関0.7以上のペアは
     同一セクター扱い

4. ETF戦略のバックテスト検証:
   - Phase 0と並行して、セクターモメンタム戦略の
     過去3年バックテストを実施（LLM不要、テクニカルのみ）
   - 20日リターンランキング上位2セクター戦略のシャープレシオを算出
   - SR < 0.3の場合: ETF戦略は採用せず、決算期間外はOption B（現金待機）
```

#### エッジへの影響

ETF補完戦略は「決算シーズン外のシグナル枯渇」への対応だが、エッジの源泉がメイン戦略と異なる（LLMセンチメント vs セクターモメンタム）。2つの異なるエッジを組み合わせることでポートフォリオ全体のシャープレシオが向上する可能性があるが、ETF戦略自体にエッジがなければ「ノイズの追加」に過ぎない。バックテスト検証なしでのETF戦略導入は、検証済みのメイン戦略のパフォーマンスを希釈するリスクがある。

---

### 論点6: 決算シーズン外の「シグナル枯渇」問題への対応策

#### 現状の問題

v2では決算期間外の運用をOption A（ETFモメンタム + マクロイベント限定）とOption B（現金100%待機）の選択肢で提示しているが、これは「決算ドリブン戦略の構造的弱点」への対症療法に過ぎない。

年間の決算シーズンは4回（1月後半-2月、4月後半-5月、7月後半-8月、10月後半-11月）で、各約3-4週間。つまり年間12-16週間がピークシーズン、残りの36-40週間（約7-8ヶ月）は「シグナル枯渇期間」。資本稼働率は30-40%に留まる。

エッジはどこにあるか？ -- 決算ドリブンのエッジが年の1/3しか使えないなら、年率8-12%の目標達成には決算シーズン中に年率24-36%相当のリターンを上げる必要がある。これは非現実的。

#### 改善提案

```
シグナル枯渇問題への3段階アプローチ

第1段階: 決算シーズンの「ロングテール」活用（即時実装可能）
  - 決算シーズンは「ピーク3週間」だけではない
  - S&P500の500銘柄の決算は約6週間にわたって分散
  - ユニバース50-80銘柄なら、ピーク前後の2-3週間にも
    月5-10件のシグナルが発生
  - シーズン間の「完全な空白」は実質2-3ヶ月に縮小

第2段階: マクロイベントドリブンの追加（Phase 2以降）
  - 対象イベント: FOMC（年8回）、CPI（毎月）、雇用統計（毎月）、
    ISM製造業/非製造業（毎月）
  - シグナル生成方法:
    1. イベント前: LLMでマクロ環境を分析、セクター影響を予測
    2. イベント後30分: 市場反応とLLM予測の乖離を検出
    3. 乖離あり → セクターETFでエントリー
  - 注意: マクロイベントへのLLMの予測力は決算分析より低い可能性が高い
    → Phase 0で別途検証（20イベント x $0.03 = $0.60）

第3段階: 「ガイダンス更新」「アナリストレーティング変更」シグナルの追加
  ★v3新規★
  - 決算シーズン外でもファンダメンタルズ変化は発生する
  - Alpaca News APIで以下をキーワード監視:
    a. "guidance update", "revised outlook", "pre-announcement"
    b. "upgrade", "downgrade", "initiating coverage"
    c. "FDA approval", "contract win", "patent ruling"
  - これらのイベントに対してLLMセンチメント分析を適用
  - 決算ドリブンと同じ仮説の延長線:
    「LLMがポジティブ判定 + 市場の初期反応がネガティブ → リバウンド」
  - 追加シグナル見込み: 月3-5件

推定年間シグナル分布（改善後）:
  | 期間              | シグナル/月 | 月数 | 年間合計 |
  |------------------|----------|-----|---------|
  | 決算ピーク（4回）    | 12-15    | 4   | 48-60   |
  | 決算周辺            | 5-8      | 4   | 20-32   |
  | シーズン外（マクロ+ニュース） | 3-6 | 4   | 12-24   |
  | 合計              |          | 12  | 80-116  |

  → 年間80-116シグナル。12ヶ月で目標300取引には不足だが、
    200取引の達成は現実的。
```

#### エッジへの影響

シグナル枯渇は年率リターンを直接制約する。決算ドリブンのエッジに依存する以上、シグナルの多様化は不可避。ただし、第2・第3段階のシグナルはエッジの検証が不十分な状態で導入するリスクがある。推奨は「Phase 0で決算シグナルのエッジを確認 → Phase 1-2でマクロ・ニュースシグナルの精度を並行測定 → Phase 3で統合」の段階的導入。

---

### 論点7: 目標リターン8-12%とKelly基準の整合性の再検証

#### 現状の問題

v2のKelly基準セクション（strategy.md セクション9）で試算された結果:

```
仮定: 勝率55%, RR比1.5
Kelly% = 25%, Half Kelly = 12.5%
現在のリスク設定: 1.0%（Kelly比4%）
年間期待リターン: 約4-6%（取引コスト前）
```

これは年率8-12%の目標と整合していない。v2自身が「年率8-12%を達成するには、勝率60%以上 or RR比2.0以上 or 年間取引数100回以上のいずれかが必要」と認めている。

問題は3つ:
1. **勝率55%の仮定が楽観的か保守的か不明**: Phase 0で検証する前に目標リターンが設定されている循環論法。
2. **取引コストの影響が過小評価**: スリッページバッファ30%は計上しているが、スプレッドコスト（0.02-0.05%/往復）、指値注文の約定逸失コスト（フィル率80%なら20%のシグナルを逃す）を含めると、年間1-3%のリターン低下。
3. **Kelly基準は「期待値最大化」であり、「目標リターン達成確率」ではない**: 目標リターンの達成確率を議論するなら、期待リターンの分布（シミュレーション）が必要。

#### 改善提案

```
Kelly基準 - 目標リターン整合性の解決

1. Phase 0結果に基づくリターンレンジの再計算:
   Phase 0で得られた実績値を使ってKelly基準を再計算し、
   目標リターンを事後的に調整する（順序の逆転）。

   目標リターン = f(実績勝率, 実績RR比, 想定取引頻度, 取引コスト)

   目標リターンを「事前に決める」のではなく、
   「検証結果から導出する」方式に変更。

2. シナリオ別リターン早見表 ★v3新規★:
   | 勝率  | RR比 | 年間取引数 | 取引コスト | 年率リターン（概算） |
   |------|------|----------|----------|-----------------|
   | 55%  | 1.5  | 80       | 1.5%     | 3.0-4.5%        |
   | 55%  | 2.0  | 80       | 1.5%     | 5.5-7.0%        |
   | 60%  | 1.5  | 80       | 1.5%     | 6.0-8.0%        |
   | 60%  | 2.0  | 80       | 1.5%     | 9.0-11.0%       |
   | 60%  | 2.0  | 120      | 2.0%     | 11.0-14.0%      |
   | 65%  | 1.5  | 80       | 1.5%     | 9.5-12.0%       |

   → 年率8-12%を達成するには:
     a. 勝率60% + RR比2.0 + 年間80取引（最低ライン）
     b. 勝率65% + RR比1.5 + 年間80取引
     c. 勝率60% + RR比2.0 + 年間120取引

   Phase 0の結果が (a)-(c) のいずれかに該当しない場合、
   目標リターンを5-8%に再度引き下げるか、
   戦略パラメータ（特にRR比 = テイクプロフィット幅）を調整。

3. テイクプロフィットの再検討:
   現在: ATR x 3.0（RR比 = 3.0/2.0 = 1.5）
   改善案: ATR x 4.0に拡大（RR比 = 4.0/2.0 = 2.0）

   トレードオフ:
   - テイクプロフィットを広げると勝率は低下する
   - ただし、PEADの60日持続性（Bernard & Thomas 1989）を考慮すると、
     5日間で ATR x 4.0 のドリフトは大型株の決算サプライズ後に十分起きうる
   - Phase 1のペーパートレーディングで ATR x 3.0 vs ATR x 4.0 の
     A/Bテストを実施（ただし「1変数ずつ」ルールに従い、
     最初の2ヶ月はATR x 3.0で運用し、3ヶ月目にATR x 4.0に変更して比較）

4. 「取引コスト込みネットリターン」での目標設定:
   v2の目標: 年率8-12%（取引コスト控除前か後か不明確）
   v3推奨: 「取引コスト込みネットリターン」で目標設定
   年率ネットリターン目標: 6-10%
   取引コスト見込み: 年率1.5-2.5%
   年率グロスリターン必要値: 7.5-12.5%
```

#### エッジへの影響

Kelly基準との整合性は「エッジの大きさに見合った期待を持つ」ための規律。エッジはどこにあるか？ -- エッジの大きさ（勝率とRR比）がわからない段階で目標リターンを固定するのは本末転倒。Phase 0の結果を待って目標を校正する「結果ドリブンの目標設定」が正しいアプローチ。

---

## 最終提言

v2で骨格が整った今、v3で最も重要なのは「実行精度」と「持続可能性」だ。優先順位順に3項目を提言する。

### 1. Phase 0の実行プロトコルを本稿の水準まで精緻化せよ（最優先）

エッジはどこにあるか？ -- Phase 0がその答えを出す。しかし、プロトコルが粗ければ答えの信頼性が低い。特に時間バイアス検定（LLMの事前知識汚染の検出）は、省略すれば「精度が高く見えるが実はLLMが答えを知っていた」という致命的な誤判断につながる。Go/No-Go判断の境界ケース（精度59%、FinBERTとの差4pp）での判断ルールも事前に文書化し、判断時の恣意性を排除せよ。

### 2. Alpha Decayモニタリングフレームワークを初月から稼働させよ

LLMセンチメントのエッジは時間とともに確実に消失する。これは「もし」ではなく「いつ」の問題。月次精度トラッキングを初月から開始し、3ヶ月移動平均の低下トレンドを早期に検出する仕組みを構築せよ。エッジ半減期の推定は6ヶ月後に初回実施。半減期が12ヶ月未満と推定された場合は、プランCへの移行（LLMの役割をシグナル生成からリスクフィルターに転換）を開始せよ。

### 3. 目標リターンをPhase 0結果に基づいて事後的に校正せよ

年率8-12%の目標はKelly基準との整合性に疑義がある。Phase 0で実績勝率とRR比が判明した時点で、シナリオ別リターン早見表に照らして目標を再校正せよ。目標リターンは「願望」ではなく「数学的に到達可能な範囲」から設定すべきだ。Phase 0の結果が勝率55%・RR比1.5を下回る場合は、目標を年率5-8%に再引き下げるか、テイクプロフィット幅の拡大（ATR x 3.0 → ATR x 4.0）を検討せよ。

---

*「エッジはどこにあるか？」 -- v2で「ここにあるかもしれない」と指差した。v3の問いは「それはいつまでそこにあるか」だ。エッジの存在を証明するのはPhase 0の仕事。エッジの持続可能性を監視するのはv3で提案したフレームワークの仕事。エッジが消えたときに何をするかを事前に決めておくのは、戦略家としての最低限の仕事だ。*
